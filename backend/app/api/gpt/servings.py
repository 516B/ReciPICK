# app/api/gpt/servings.py

from fastapi import APIRouter
from pydantic import BaseModel
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
router = APIRouter()

class ServingsRequest(BaseModel):
    ingredients: list[str]
    steps: list[str]
    current_serving: str
    target_serving: str

@router.post("/servings")
async def convert_servings(req: ServingsRequest):
    try:
        prompt = (
            f"ë‹¤ìŒì€ {req.current_serving} ê¸°ì¤€ ë ˆì‹œí”¼ì…ë‹ˆë‹¤.\n"
            f"{req.target_serving} ê¸°ì¤€ìœ¼ë¡œ ì¬ë£Œ ì–‘ê³¼ ì¡°ë¦¬ ë‹¨ê³„ë¥¼ ëª¨ë‘ ì•Œë§ê²Œ ì¡°ì •í•´ ì£¼ì„¸ìš”.\n\n"
            f"ğŸ§¾ ì¬ë£Œ ëª©ë¡:\n" + "\n".join(req.ingredients) +
            f"\n\nğŸ‘¨â€ğŸ³ ì¡°ë¦¬ ìˆœì„œ:\n" + "\n".join(f"{i+1}. {s}" for i, s in enumerate(req.steps))
        )

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ìš”ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë ˆì‹œí”¼ë¥¼ ì›í•˜ëŠ” ì¸ë¶„ì— ë§ê²Œ ì¡°ì •í•´ ì£¼ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ]

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.5,
            max_tokens=1000,
        )

        return {"result": response.choices[0].message.content.strip()}

    except Exception as e:
        return {"error": str(e)}
